{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Giantstride\\Desktop\\AInfinity\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet\n",
      "0  @miss_simmons1 @CooperativeBank @HSBC Donât ...\n",
      "1  @HSBC_UK I wish HSBC had been able to honour t...\n",
      "2  @AshDMcarp HSBC is the worst, I tried calling ...\n",
      "3  @HSBC_UK If you want the worlds worst mortgage...\n",
      "4  @justleeuk @cliveedwards10 @Ens_007 @HSBC_UK @...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"C:/Users/Giantstride/Desktop/AInfinity/Bad reputation.csv\",encoding='latin1')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = df.astype(str) \n",
    "print(data.dtypes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(tweet):\n",
    "    #Remove RT\n",
    "    tweet = re.sub(r'RT', '', tweet)\n",
    "    \n",
    "    #Fix &\n",
    "    tweet = re.sub(r'&amp;', '&', tweet)\n",
    "    \n",
    "    #Remove punctuations\n",
    "    tweet = re.sub(r'[?!.;:,#@-]', '', tweet)\n",
    "\n",
    "    #Convert to lowercase to maintain consistency\n",
    "    tweet = tweet.lower()\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_text'] = data.tweet.apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = ['a', 'about', 'above', 'after', 'again', 'against', 'all', 'also', 'am', 'an', 'and',\n",
    "              'any', 'are', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below',\n",
    "              'between', 'both', 'but', 'by', 'can', \"can't\", 'cannot', 'com', 'could', \"couldn't\", 'did',\n",
    "              \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during', 'each', 'else', 'ever',\n",
    "              'few', 'for', 'from', 'further', 'get', 'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having',\n",
    "              'he', \"he'd\", \"he'll\", \"he's\", 'her', 'here', \"here's\", 'hers', 'herself', 'him', 'himself', 'his', 'how',\n",
    "              \"how's\", 'however', 'http', 'i', \"i'd\", \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'into', 'is', \"isn't\", 'it',\n",
    "              \"it's\", 'its', 'itself', 'just', 'k', \"let's\", 'like', 'me', 'more', 'most', \"mustn't\", 'my', 'myself',\n",
    "              'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'otherwise', 'ought', 'our', 'ours',\n",
    "              'ourselves', 'out', 'over', 'own', 'r', 'same', 'shall', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\",\n",
    "              'should', \"shouldn't\", 'since', 'so', 'some', 'such', 'than', 'that', \"that's\", 'the', 'their', 'theirs',\n",
    "              'them', 'themselves', 'then', 'there', \"there's\", 'these', 'they', \"they'd\", \"they'll\", \"they're\",\n",
    "              \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was', \"wasn't\",\n",
    "              'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\", 'what', \"what's\", 'when', \"when's\", 'where',\n",
    "              \"where's\", 'which', 'while', 'who', \"who's\", 'whom', 'why', \"why's\", 'with', \"won't\", 'would', \"wouldn't\",\n",
    "              'www', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']\n",
    "\n",
    "#Generate word frequency\n",
    "def gen_freq(tweet):\n",
    "    #Will store the list of words\n",
    "    word_list = []\n",
    "\n",
    "    #Loop over all the tweets and extract words into word_list\n",
    "    for tw_words in tweet.split():\n",
    "        word_list.extend(tw_words)\n",
    "\n",
    "    #Create word frequencies using word_list\n",
    "    word_freq = pd.Series(word_list).value_counts()\n",
    "    \n",
    "    #Drop the stopwords during the frequency calculation\n",
    "    word_freq = word_freq.drop(STOP_WORDS, errors='ignore')\n",
    "    \n",
    "    return word_freq\n",
    "\n",
    "#Check whether a negation term is present in the text\n",
    "def any_neg(words):\n",
    "    for word in words:\n",
    "        if word in ['n', 'no', 'non', 'not'] or re.search(r\"\\wn't\", word):\n",
    "            return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#Check whether one of the 100 rare words is present in the text\n",
    "def any_rare(words, rare_100):\n",
    "    for word in words:\n",
    "        if word in rare_100:\n",
    "            return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#Check whether prompt words are present\n",
    "def is_question(words):\n",
    "    for word in words:\n",
    "        if word in ['when', 'what', 'how', 'why', 'who']:\n",
    "            return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = gen_freq(data.clean_text.str)\n",
    "#100 most rare words in the dataset\n",
    "rare_100 = word_freq[-100:]\n",
    "#Number of words in a tweet\n",
    "data['word_count'] = data.clean_text.str.split().apply(lambda x: len(x))\n",
    "#Negation present or not\n",
    "data['any_neg'] = data.clean_text.str.split().apply(lambda x: any_neg(x))\n",
    "#Prompt present or not\n",
    "data['is_question'] = data.clean_text.str.split().apply(lambda x: is_question(x))\n",
    "#Any of the most 100 rare words present or not\n",
    "data['any_rare'] = data.clean_text.str.split().apply(lambda x: any_rare(x, rare_100))\n",
    "#Character count of the tweet\n",
    "data['char_count'] = data.clean_text.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hsbc              70\n",
       "hsbc_uk           45\n",
       "worst             39\n",
       "service           26\n",
       "customer          24\n",
       "bank              21\n",
       "awful             19\n",
       "worse             15\n",
       "banks             12\n",
       "applied           11\n",
       "&                 11\n",
       "time              11\n",
       "account           11\n",
       "help              11\n",
       "money             11\n",
       "even              11\n",
       "will              10\n",
       "disappointed      10\n",
       "years             10\n",
       "now                9\n",
       "banking            9\n",
       "hsbcukbusiness     9\n",
       "waiting            9\n",
       "business           9\n",
       "got                8\n",
       "switch             8\n",
       "us                 8\n",
       "weeks              8\n",
       "know               8\n",
       "today              7\n",
       "barclays           7\n",
       "card               7\n",
       "customers          7\n",
       "ago                7\n",
       "bbl                7\n",
       "hold               7\n",
       "seems              6\n",
       "first              6\n",
       "never              6\n",
       "trying             6\n",
       "still              6\n",
       "starlingbank       6\n",
       "hsbc_in            6\n",
       "canât            6\n",
       "day                6\n",
       "app                6\n",
       "make               5\n",
       "lot                5\n",
       "hours              5\n",
       "use                5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top 10 common words are\n",
    "gen_freq(data.clean_text.str)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = gen_freq(''.join(str(df['tweet'].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)        11\n",
       "(12, 12)       6\n",
       "(3, 3)         3\n",
       "(16, 16)       2\n",
       "(197, 192)     1\n",
       "(24, 24)       1\n",
       "(19, 18)       1\n",
       "(166, 156)     1\n",
       "(7, 6)         1\n",
       "(35, 33)       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.Series(nltk.ngrams(words, 2)).value_counts())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
